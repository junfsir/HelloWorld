### 地址空间

地址空间是所有可用资源的集合，可以划分为物理地址空间和线性地址空间两大类；

1. 物理地址空间

硬件平台通常划分为CPU、内存和其他硬件设备三个部分。其中，CPU是整个硬件平台的主导者，内存和其他硬件设备都是CPU可以使用的资源。这些资源组合在一起，分布在 CPU 的物理地址空间内，CPU 使用物理地址索引这些资源。物理地址空间的大小由CPU实现的物理地址位数所决定，物理地址位数由CPU经过MMU（Memory ManagementUnit，内存管理单元）转换后的外地址总线位数决定。

一个硬件平台只有一个物理地址空间，但每个程序都认为自己独享整个平台的硬件资源。为了让多个程序能够有效地相互隔离，也为了它们能够有效地使用物理地址空间的资源，引入了线性地址空间的概念。

2. 线性地址空间

线性地址空间的大小由CPU实现的线性地址位数所决定，线性地址位数由CPU 的内地址总线位数决定。需要注意的是，线性地址空间的大小与物理地址空间的大小没有必然联系，Intel 的PAE平台具有4GB的线性地址空间，而其物理地址空间为64GB。

线性地址空间会被映射到某一部分物理地址空间或整个物理地址空间。一个硬件平台上可以有多个线性地址空间，CPU负责将线性地址空间转换成物理地址空间，保证程序能够正确访问到该线性地址空间所映射到的物理地址空间。在现代操作系统中，每个进程通常都拥有自己的私有线性地址空间。一个典型的线性地址空间构造如图所示。

![](https://github.com/junfsir/jNote/raw/master/images/线性地址空间构造.jpg)

### 地址

地址是访问地址空间的索引。根据访问地址空间的不同，索引可以分为物理地址和线性地址。但由于x86特殊的段机制，还存在一种额外的地址—逻辑地址。

1. 逻辑地址

逻辑地址是程序直接使用的地址（x86 无法禁用段机制，逻辑地址一直存在）。逻辑地址由一个16位的段选择符和一个32位的偏移量（32位平台）构成。

2. 线性地址

线性地址又称虚拟地址。线性地址是逻辑地址转换后的结果，用于索引线性地址空间。当 CPU 使用分页机制时，还需要将线性地址转换成物理地址才能访问平台内存或其他硬件设备；当分页机制未启用时，线性地址与物理地址相同。

3. 物理地址

物理地址是物理地址空间的索引，是CPU提交到总线用于访问平台内存或其他硬件设备的最终地址，在x86下，物理地址有时也被称为总线地址。

物理地址与逻辑地址、线性地址的关系总结如下：

- 分段机制启用，分页机制未启用：逻辑地址→线性地址=物理地址
- 分段机制、分页机制同时启用：逻辑地址→线性地址→物理地址

### x86内存管理机制

x86架构的内存管理机制分为两部分：分段机制和分页机制。

分段机制为程序提供彼此隔离的代码区域、数据区域、栈区域，从而避免了同一个处理器上运行的多个程序互相影响。

分页机制实现了传统的按需分页、虚拟内存机制，可以将程序的执行环境按需映射到物理内存。此外，分页机制还可以用于提供多任务的隔离。分段机制和分页机制都可以通过配置支持简单的单任务系统、多任务系统或共享内存的多处理器系统。需要强调的一点是，处理器无论在何种运行模式下都不可以禁止分段机制，但是分页机制却是可选选项。

1. 分段机制

分段机制将内存划分成以起始地址（Base）和长度（Limit）描述的块。段可以与程序最基本的元素联系起来，程序可以简单地划分为代码段、数据段和栈，段机制就有相应的代码段、数据段和栈段。

分段机制由逻辑地址、段选择符、段描述符和段描述符表4个基本部分构成。当程序使用逻辑地址访问内存的某个部分时，CPU通过逻辑地址中的段选择符索引段描述符表，进而得到该内存对应的段描述符（段描述符描述段的基地址、长度以及读/写、访问权限等属性信息），根据段描述符中的段属性信息检测程序的访问是否合法，如果合法，再根据段描述符中的基地址将逻辑地址转换为线性地址。这个流程可以用下图概括。

![](https://github.com/junfsir/jNote/raw/master/images/分段机制流程分布.jpg)

2. 分页机制

分段机制将内存划分成以基地址和长度描述的多个段进行管理，对应的逻辑地址以基地址和偏移量来描述。而分页机制是更加粒度化的内存管理机制，使用粒度化的单位“页”来管理线性地址空间和物理地址空间的对应关系。同时，分页机制允许一个页面存放在物理内存中或磁盘的交换区域（如Linux下的Swap分区，Windows下的虚拟内存文件）中，程序可以使用比机器物理内存更大的内存区域，从而使现代操作系统中虚拟内存机制的实现成为可能。

分页机制的核心思想是通过页表将线性地址转换为物理地址，并配合旁路转换缓冲区（Translation LookasideBuffer，后面简称为TLB）来加速地址转换的过程。分页机制主要由页表、CR3寄存器和TLB三个部件构成，其流程如图所示。

![](https://github.com/junfsir/jNote/raw/master/images/分页机制流程分布.jpg)

### x86-64的基本模式

传统的IA-32模式下，x86有三种运行模式：实模式、保护模式和虚拟8086模式。

- 实模式：是Intel 8086处理器工作的模式。在该模式下，逻辑地址转换后就是物理地址，操作系统或BIOS通常在该模式下准备必要的数据结构和初始化关键的寄存器，然后再切换入保护模式。
- 保护模式：操作系统运行时最常用的模式。在该模式下，CPU的所有功能几乎都能得到使用，可以访问架构允许的所有物理地址空间。
- 虚拟 8086模式：该模式让 CPU在保护模式下为8086程序虚拟实模式的运行环境，使这些程序在执行时无须从保护模式切换到实模式。

### 中断与异常

1. 中断架构

中断机制使外部硬件设备可以打断CPU当前的执行任务，使CPU为自己提供服务。

中断从设备经由“中断控制器”转发给CPU（MSI除外）。中断控制器发展至今，经历了PIC（ProgrammableInterrupt Controller，可编程中断控制器）和APIC（Advanced Programmable InterruptController，高级可编程中断控制器）两个阶段。

2. 异常架构

中断由外部设备产生，和CPU当前执行的指令无关。异常由CPU内部产生，其原因是CPU当前执行的指令出了问题。

异常根据产生的原因和严重性可以分为如下三类。

- 错误（Fault）：由某种错误情况引起，一般可以被错误处理程序纠正。错误发生时，处理器将控制权交由对应的处理程序。前面所讲的缺页错误就属于此类。
- 陷阱（Trap）：指在执行了一条特殊指令后引起的异常。陷阱是有意的异常，陷阱最重要的用途是在用户程序和内核之间提供一个像过程一样的接口（即系统调用）。Linux中用于实现系统调用的INT 80 指令就属于此类。
- 终止（Abort）：指严重的不可恢复的错误，将导致程序终止。典型的是一些硬件错误。

### I/O架构

计算机所处理的任务其实只有两种：CPU运算和I/O操作。

I/O（输入/输出）是CPU访问外部设备的方法。设备通常通过寄存器和设备RAM将自身功能展现给CPU，CPU通过读/写这些寄存器和RAM完成对设备的访问及其他操作。

### DMA

直接内存访问（Direct Memory Access，后文简称为DMA）是所有现代计算机的重要特色。DMA允许设备绕开CPU直接向内存中复制或读取数据。如果设备向内存复制数据都经过CPU，则CPU会有大量中断负载，中断过程中， CPU对其他任务来讲无法使用，不利于系统性能的提高。通过DMA，CPU只负责初始化这个传输动作，而传输动作本身由 DMA 控制器（后文简称为DMAC）来实行和完成。在实现 DMA 传输时，由 DMAC 直接控制总线，在DMA 传输前，CPU 要把总线控制权交给 DMAC，结束DMA 传输后，DMAC立即把总线控制权交回给CPU。